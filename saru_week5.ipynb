{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "saru_week5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_973_N3oUyn"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDOwm4iwi7-k"
      },
      "source": [
        "# **Fetching a data from given link**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZe5tmmTiidz"
      },
      "source": [
        "url = 'https://github.com/barnysanchez/clarku-assignment4/raw/main/inputANDoutputs.csv'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGSxFA9hr3-9"
      },
      "source": [
        "# input data  (student to implement fetch function to grab inputs/outputs file and transform accordingly)\n",
        "# The location to fecth data is:  https://github.com/barnysanchez/clarku-assignment4/raw/main/inputANDoutputs.csv\n",
        "def fetch(url):\n",
        "  data = pd.read_csv(url,sep=',')\n",
        "  input = data.iloc[:,:-1].to_numpy()\n",
        "  # output data\n",
        "  output = data['output'].to_numpy().reshape(-1,1)\n",
        "  return input, output\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MY5-Nxky5jO"
      },
      "source": [
        "inputs, outputs = fetch(url)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdGnW5am2etG",
        "outputId": "2ae7b229-a3ed-40cd-82ca-4c2bba537403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "inputs"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 1, 1],\n",
              "       [1, 0, 1],\n",
              "       [1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q0pM8EP2giw",
        "outputId": "acb944a5-5534-4b20-c5bd-9f7dfa0052d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "outputs"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K3WpViLjzz4"
      },
      "source": [
        "# **Determine the number of epochs needed to achieve 99% prediction accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeK6RV5yqu34"
      },
      "source": [
        "# create NeuralNetwork class\n",
        "class NeuralNetwork:\n",
        "\n",
        "    # intialize variables in class\n",
        "    def __init__(self, inputs, outputs):\n",
        "        self.inputs  = inputs\n",
        "        self.outputs = outputs\n",
        "        # initialize weights as .50 for simplicity\n",
        "        self.weights = np.array([[.50], [.50], [.50]])\n",
        "        self.error_history = []\n",
        "        self.epoch_list = []\n",
        "\n",
        "    #activation function ==> S(x) = 1/1+e^(-x)\n",
        "    def sigmoid(self, x, deriv=False):\n",
        "        if deriv == True:\n",
        "            return x * (1 - x)\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # data will flow through the neural network.\n",
        "    def feed_forward(self):\n",
        "        self.hidden = self.sigmoid(np.dot(self.inputs, self.weights))\n",
        "\n",
        "    # going backwards through the network to update weights\n",
        "    def backpropagation(self):\n",
        "        self.error  = self.outputs - self.hidden\n",
        "        delta = self.error * self.sigmoid(self.hidden, deriv=True)\n",
        "        self.weights = self.weights + np.dot(self.inputs.T, delta)\n",
        "\n",
        "    # train the neural net for 5 iterations\n",
        "    def train(self, epochs=5):\n",
        "        for epoch in range(epochs):\n",
        "            # flow forward and produce an output\n",
        "            self.feed_forward()\n",
        "            # go back though the network to make corrections based on the output\n",
        "            self.backpropagation()    \n",
        "            # keep track of the error history over each epoch\n",
        "            presentError = np.average(np.abs(self.error))\n",
        "            accuracy = 1 - presentError\n",
        "            self.error_history.append(presentError)\n",
        "            self.epoch_list.append(epoch)\n",
        "            if accuracy >= 0.99:\n",
        "              print (f'Epoch: {epoch} \\nAccuracy: {accuracy}')\n",
        "              print(f'The required epoch to get 99% accuracy is {epoch}')\n",
        "              break\n",
        "\n",
        "    # function to predict output on new and unseen input data                               \n",
        "    def predict(self, new_input):\n",
        "        prediction = self.sigmoid(np.dot(new_input, self.weights))\n",
        "        return prediction\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75efMUh3q8US",
        "outputId": "19b29ab7-6764-4e07-b9a1-0148cf63002a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# create neural network   \n",
        "NN = NeuralNetwork(inputs, outputs)\n",
        "# train neural network\n",
        "NN.train(5000)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4058 \n",
            "Accuracy: 0.9900012868022382\n",
            "The required epoch to get 99% accuracy is 4058\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6k7ZEW5rBC_"
      },
      "source": [
        "# create two new examples to predict                                   \n",
        "example = np.array([[1, 0, 0]])\n",
        "example_2 = np.array([[0, 1, 1]])\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-naqwJ-yeeQ",
        "outputId": "1c5362b5-f624-4beb-8833-bfb004ce91ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# print the predictions for both examples                                   \n",
        "print(NN.predict(example), ' - Correct: ', example[0][0])\n",
        "print(NN.predict(example_2), ' - Correct: ', example_2[0][0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99967599]]  - Correct:  1\n",
            "[[0.00415332]]  - Correct:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ztilOmpyeqd",
        "outputId": "688009a9-a9c5-4ee9-fa16-4ed930565d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# plot the error over the entire training duration\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(NN.epoch_list, NN.error_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKkNYc1-kJnX"
      },
      "source": [
        "# **Determine the number of epochs needed to achieve 99% prediction accuracy with softmax function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeZ8oTrWM4tG"
      },
      "source": [
        "# create NeuralNetwork class for softmax\n",
        "class SoftNeuralNetwork:\n",
        "\n",
        "    # intialize variables in class\n",
        "    def __init__(self, inputs, outputs):\n",
        "        self.inputs  = inputs\n",
        "        self.outputs = outputs\n",
        "        # initialize weights as .50 for simplicity\n",
        "        self.weights = np.array([[.50], [.50], [.50]])\n",
        "        self.error_history = []\n",
        "        self.epoch_list = []\n",
        "\n",
        "    #activation function\n",
        "    def softmax(self, x, deriv=False):\n",
        "        if deriv == True:\n",
        "            return x * (1 - x)\n",
        "        return np.exp(x)/sum(np.exp(x))\n",
        "\n",
        "    # data will flow through the neural network.\n",
        "    def feed_forward(self):\n",
        "        self.hidden = self.softmax(np.dot(self.inputs, self.weights))\n",
        "\n",
        "    # going backwards through the network to update weights\n",
        "    def backpropagation(self):\n",
        "        self.error  = self.outputs - self.hidden\n",
        "        delta = self.error * self.softmax(self.hidden, deriv=True)\n",
        "        self.weights = self.weights + np.dot(self.inputs.T, delta)\n",
        "\n",
        "    # train the neural net for 5 iterations\n",
        "    def train(self, epochs=5):\n",
        "        for epoch in range(epochs):\n",
        "            # flow forward and produce an output\n",
        "            self.feed_forward()\n",
        "            # go back though the network to make corrections based on the output\n",
        "            self.backpropagation()    \n",
        "            # keep track of the error history over each epoch\n",
        "            presentError = np.average(np.abs(self.error))\n",
        "            accuracy = 1 - presentError\n",
        "            print (f'Epoch: {epoch} \\nAccuracy: {accuracy}')\n",
        "            self.error_history.append(presentError)\n",
        "            self.epoch_list.append(epoch)\n",
        "            if accuracy >= 0.99:\n",
        "              print (f'Epoch: {epoch} \\nAccuracy: {accuracy}')\n",
        "              print(f'The required epoch to get 99% accuracy is {epoch}')\n",
        "              break\n",
        "\n",
        "    # function to predict output on new and unseen input data                               \n",
        "    def predict(self, new_input):\n",
        "        prediction = self.softmax(np.dot(new_input, self.weights))\n",
        "        return prediction\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiRpWONbNyok",
        "outputId": "40932711-f683-44a2-88fd-70aff6230df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "softNN = SoftNeuralNetwork(inputs,outputs)\n",
        "softNN.train(500)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \n",
            "Accuracy: 0.5\n",
            "Epoch: 1 \n",
            "Accuracy: 0.5364331793542543\n",
            "Epoch: 2 \n",
            "Accuracy: 0.5699746064359461\n",
            "Epoch: 3 \n",
            "Accuracy: 0.5995635684637401\n",
            "Epoch: 4 \n",
            "Accuracy: 0.6248450708266455\n",
            "Epoch: 5 \n",
            "Accuracy: 0.6459739346756797\n",
            "Epoch: 6 \n",
            "Accuracy: 0.6633937943985806\n",
            "Epoch: 7 \n",
            "Accuracy: 0.6776590505031272\n",
            "Epoch: 8 \n",
            "Accuracy: 0.6893207658748173\n",
            "Epoch: 9 \n",
            "Accuracy: 0.6988694927340733\n",
            "Epoch: 10 \n",
            "Accuracy: 0.7067164233607883\n",
            "Epoch: 11 \n",
            "Accuracy: 0.7131950628388375\n",
            "Epoch: 12 \n",
            "Accuracy: 0.7185714091780544\n",
            "Epoch: 13 \n",
            "Accuracy: 0.7230561507783769\n",
            "Epoch: 14 \n",
            "Accuracy: 0.7268160003821691\n",
            "Epoch: 15 \n",
            "Accuracy: 0.7299832046867123\n",
            "Epoch: 16 \n",
            "Accuracy: 0.7326631408119962\n",
            "Epoch: 17 \n",
            "Accuracy: 0.7349402386246511\n",
            "Epoch: 18 \n",
            "Accuracy: 0.7368825470590356\n",
            "Epoch: 19 \n",
            "Accuracy: 0.7385452426916151\n",
            "Epoch: 20 \n",
            "Accuracy: 0.7399733282595142\n",
            "Epoch: 21 \n",
            "Accuracy: 0.7412037156866216\n",
            "Epoch: 22 \n",
            "Accuracy: 0.7422668422838771\n",
            "Epoch: 23 \n",
            "Accuracy: 0.7431879322215729\n",
            "Epoch: 24 \n",
            "Accuracy: 0.7439879873602349\n",
            "Epoch: 25 \n",
            "Accuracy: 0.744684570491235\n",
            "Epoch: 26 \n",
            "Accuracy: 0.7452924283865764\n",
            "Epoch: 27 \n",
            "Accuracy: 0.7458239904467255\n",
            "Epoch: 28 \n",
            "Accuracy: 0.7462897701161382\n",
            "Epoch: 29 \n",
            "Accuracy: 0.7466986898176358\n",
            "Epoch: 30 \n",
            "Accuracy: 0.7470583453551871\n",
            "Epoch: 31 \n",
            "Accuracy: 0.7473752221228865\n",
            "Epoch: 32 \n",
            "Accuracy: 0.7476548727248143\n",
            "Epoch: 33 \n",
            "Accuracy: 0.7479020635293023\n",
            "Epoch: 34 \n",
            "Accuracy: 0.7481208960863276\n",
            "Epoch: 35 \n",
            "Accuracy: 0.7483149081069598\n",
            "Epoch: 36 \n",
            "Accuracy: 0.7484871577495957\n",
            "Epoch: 37 \n",
            "Accuracy: 0.7486402942129149\n",
            "Epoch: 38 \n",
            "Accuracy: 0.7487766170507839\n",
            "Epoch: 39 \n",
            "Accuracy: 0.7488981261627516\n",
            "Epoch: 40 \n",
            "Accuracy: 0.7490065640474644\n",
            "Epoch: 41 \n",
            "Accuracy: 0.7491034516141486\n",
            "Epoch: 42 \n",
            "Accuracy: 0.7491901186131393\n",
            "Epoch: 43 \n",
            "Accuracy: 0.7492677295578924\n",
            "Epoch: 44 \n",
            "Accuracy: 0.7493373058584605\n",
            "Epoch: 45 \n",
            "Accuracy: 0.7493997447626195\n",
            "Epoch: 46 \n",
            "Accuracy: 0.7494558355999241\n",
            "Epoch: 47 \n",
            "Accuracy: 0.7495062737413996\n",
            "Epoch: 48 \n",
            "Accuracy: 0.7495516726197868\n",
            "Epoch: 49 \n",
            "Accuracy: 0.7495925740994\n",
            "Epoch: 50 \n",
            "Accuracy: 0.749629457438489\n",
            "Epoch: 51 \n",
            "Accuracy: 0.7496627470487278\n",
            "Epoch: 52 \n",
            "Accuracy: 0.7496928192246222\n",
            "Epoch: 53 \n",
            "Accuracy: 0.7497200079890968\n",
            "Epoch: 54 \n",
            "Accuracy: 0.7497446101793365\n",
            "Epoch: 55 \n",
            "Accuracy: 0.7497668898783647\n",
            "Epoch: 56 \n",
            "Accuracy: 0.7497870822822129\n",
            "Epoch: 57 \n",
            "Accuracy: 0.7498053970793872\n",
            "Epoch: 58 \n",
            "Accuracy: 0.7498220214082207\n",
            "Epoch: 59 \n",
            "Accuracy: 0.7498371224483162\n",
            "Epoch: 60 \n",
            "Accuracy: 0.7498508496943112\n",
            "Epoch: 61 \n",
            "Accuracy: 0.7498633369534389\n",
            "Epoch: 62 \n",
            "Accuracy: 0.7498747041026\n",
            "Epoch: 63 \n",
            "Accuracy: 0.7498850586357514\n",
            "Epoch: 64 \n",
            "Accuracy: 0.7498944970282253\n",
            "Epoch: 65 \n",
            "Accuracy: 0.7499031059410094\n",
            "Epoch: 66 \n",
            "Accuracy: 0.749910963284937\n",
            "Epoch: 67 \n",
            "Accuracy: 0.7499181391621035\n",
            "Epoch: 68 \n",
            "Accuracy: 0.7499246966995514\n",
            "Epoch: 69 \n",
            "Accuracy: 0.7499306927883136\n",
            "Epoch: 70 \n",
            "Accuracy: 0.7499361787392191\n",
            "Epoch: 71 \n",
            "Accuracy: 0.7499412008654084\n",
            "Epoch: 72 \n",
            "Accuracy: 0.7499458010002469\n",
            "Epoch: 73 \n",
            "Accuracy: 0.7499500169582349\n",
            "Epoch: 74 \n",
            "Accuracy: 0.7499538829455651\n",
            "Epoch: 75 \n",
            "Accuracy: 0.7499574299261577\n",
            "Epoch: 76 \n",
            "Accuracy: 0.7499606859482904\n",
            "Epoch: 77 \n",
            "Accuracy: 0.7499636764363162\n",
            "Epoch: 78 \n",
            "Accuracy: 0.7499664244514215\n",
            "Epoch: 79 \n",
            "Accuracy: 0.7499689509249041\n",
            "Epoch: 80 \n",
            "Accuracy: 0.749971274867036\n",
            "Epoch: 81 \n",
            "Accuracy: 0.7499734135542159\n",
            "Epoch: 82 \n",
            "Accuracy: 0.7499753826968005\n",
            "Epoch: 83 \n",
            "Accuracy: 0.7499771965897226\n",
            "Epoch: 84 \n",
            "Accuracy: 0.7499788682477639\n",
            "Epoch: 85 \n",
            "Accuracy: 0.7499804095271383\n",
            "Epoch: 86 \n",
            "Accuracy: 0.7499818312348459\n",
            "Epoch: 87 \n",
            "Accuracy: 0.7499831432271025\n",
            "Epoch: 88 \n",
            "Accuracy: 0.7499843544979945\n",
            "Epoch: 89 \n",
            "Accuracy: 0.7499854732593866\n",
            "Epoch: 90 \n",
            "Accuracy: 0.7499865070129944\n",
            "Epoch: 91 \n",
            "Accuracy: 0.7499874626154317\n",
            "Epoch: 92 \n",
            "Accuracy: 0.7499883463369574\n",
            "Epoch: 93 \n",
            "Accuracy: 0.7499891639145648\n",
            "Epoch: 94 \n",
            "Accuracy: 0.7499899205999909\n",
            "Epoch: 95 \n",
            "Accuracy: 0.7499906212031547\n",
            "Epoch: 96 \n",
            "Accuracy: 0.749991270131489\n",
            "Epoch: 97 \n",
            "Accuracy: 0.7499918714255702\n",
            "Epoch: 98 \n",
            "Accuracy: 0.7499924287914181\n",
            "Epoch: 99 \n",
            "Accuracy: 0.7499929456297905\n",
            "Epoch: 100 \n",
            "Accuracy: 0.7499934250627689\n",
            "Epoch: 101 \n",
            "Accuracy: 0.7499938699579013\n",
            "Epoch: 102 \n",
            "Accuracy: 0.7499942829501345\n",
            "Epoch: 103 \n",
            "Accuracy: 0.7499946664617533\n",
            "Epoch: 104 \n",
            "Accuracy: 0.7499950227205154\n",
            "Epoch: 105 \n",
            "Accuracy: 0.7499953537761546\n",
            "Epoch: 106 \n",
            "Accuracy: 0.7499956615154062\n",
            "Epoch: 107 \n",
            "Accuracy: 0.7499959476756964\n",
            "Epoch: 108 \n",
            "Accuracy: 0.7499962138576172\n",
            "Epoch: 109 \n",
            "Accuracy: 0.7499964615363034\n",
            "Epoch: 110 \n",
            "Accuracy: 0.7499966920718122\n",
            "Epoch: 111 \n",
            "Accuracy: 0.7499969067185975\n",
            "Epoch: 112 \n",
            "Accuracy: 0.7499971066341613\n",
            "Epoch: 113 \n",
            "Accuracy: 0.7499972928869592\n",
            "Epoch: 114 \n",
            "Accuracy: 0.7499974664636263\n",
            "Epoch: 115 \n",
            "Accuracy: 0.7499976282755854\n",
            "Epoch: 116 \n",
            "Accuracy: 0.7499977791650925\n",
            "Epoch: 117 \n",
            "Accuracy: 0.7499979199107714\n",
            "Epoch: 118 \n",
            "Accuracy: 0.7499980512326814\n",
            "Epoch: 119 \n",
            "Accuracy: 0.7499981737969597\n",
            "Epoch: 120 \n",
            "Accuracy: 0.7499982882200775\n",
            "Epoch: 121 \n",
            "Accuracy: 0.7499983950727415\n",
            "Epoch: 122 \n",
            "Accuracy: 0.7499984948834724\n",
            "Epoch: 123 \n",
            "Accuracy: 0.7499985881418911\n",
            "Epoch: 124 \n",
            "Accuracy: 0.7499986753017329\n",
            "Epoch: 125 \n",
            "Accuracy: 0.7499987567836177\n",
            "Epoch: 126 \n",
            "Accuracy: 0.749998832977595\n",
            "Epoch: 127 \n",
            "Accuracy: 0.7499989042454822\n",
            "Epoch: 128 \n",
            "Accuracy: 0.7499989709230167\n",
            "Epoch: 129 \n",
            "Accuracy: 0.7499990333218332\n",
            "Epoch: 130 \n",
            "Accuracy: 0.7499990917312853\n",
            "Epoch: 131 \n",
            "Accuracy: 0.7499991464201217\n",
            "Epoch: 132 \n",
            "Accuracy: 0.7499991976380289\n",
            "Epoch: 133 \n",
            "Accuracy: 0.749999245617055\n",
            "Epoch: 134 \n",
            "Accuracy: 0.7499992905729187\n",
            "Epoch: 135 \n",
            "Accuracy: 0.7499993327062182\n",
            "Epoch: 136 \n",
            "Accuracy: 0.7499993722035461\n",
            "Epoch: 137 \n",
            "Accuracy: 0.7499994092385167\n",
            "Epoch: 138 \n",
            "Accuracy: 0.7499994439727153\n",
            "Epoch: 139 \n",
            "Accuracy: 0.749999476556574\n",
            "Epoch: 140 \n",
            "Accuracy: 0.749999507130181\n",
            "Epoch: 141 \n",
            "Accuracy: 0.7499995358240278\n",
            "Epoch: 142 \n",
            "Accuracy: 0.7499995627596996\n",
            "Epoch: 143 \n",
            "Accuracy: 0.7499995880505147\n",
            "Epoch: 144 \n",
            "Accuracy: 0.7499996118021139\n",
            "Epoch: 145 \n",
            "Accuracy: 0.7499996341130077\n",
            "Epoch: 146 \n",
            "Accuracy: 0.7499996550750809\n",
            "Epoch: 147 \n",
            "Accuracy: 0.7499996747740612\n",
            "Epoch: 148 \n",
            "Accuracy: 0.749999693289952\n",
            "Epoch: 149 \n",
            "Accuracy: 0.7499997106974337\n",
            "Epoch: 150 \n",
            "Accuracy: 0.7499997270662351\n",
            "Epoch: 151 \n",
            "Accuracy: 0.7499997424614788\n",
            "Epoch: 152 \n",
            "Accuracy: 0.7499997569439998\n",
            "Epoch: 153 \n",
            "Accuracy: 0.7499997705706416\n",
            "Epoch: 154 \n",
            "Accuracy: 0.7499997833945318\n",
            "Epoch: 155 \n",
            "Accuracy: 0.7499997954653356\n",
            "Epoch: 156 \n",
            "Accuracy: 0.749999806829494\n",
            "Epoch: 157 \n",
            "Accuracy: 0.7499998175304421\n",
            "Epoch: 158 \n",
            "Accuracy: 0.7499998276088138\n",
            "Epoch: 159 \n",
            "Accuracy: 0.7499998371026304\n",
            "Epoch: 160 \n",
            "Accuracy: 0.7499998460474784\n",
            "Epoch: 161 \n",
            "Accuracy: 0.7499998544766706\n",
            "Epoch: 162 \n",
            "Accuracy: 0.7499998624214006\n",
            "Epoch: 163 \n",
            "Accuracy: 0.7499998699108826\n",
            "Epoch: 164 \n",
            "Accuracy: 0.7499998769724837\n",
            "Epoch: 165 \n",
            "Accuracy: 0.7499998836318462\n",
            "Epoch: 166 \n",
            "Accuracy: 0.7499998899130009\n",
            "Epoch: 167 \n",
            "Accuracy: 0.7499998958384746\n",
            "Epoch: 168 \n",
            "Accuracy: 0.7499999014293869\n",
            "Epoch: 169 \n",
            "Accuracy: 0.7499999067055436\n",
            "Epoch: 170 \n",
            "Accuracy: 0.749999911685522\n",
            "Epoch: 171 \n",
            "Accuracy: 0.7499999163867503\n",
            "Epoch: 172 \n",
            "Accuracy: 0.7499999208255825\n",
            "Epoch: 173 \n",
            "Accuracy: 0.7499999250173671\n",
            "Epoch: 174 \n",
            "Accuracy: 0.7499999289765127\n",
            "Epoch: 175 \n",
            "Accuracy: 0.7499999327165476\n",
            "Epoch: 176 \n",
            "Accuracy: 0.7499999362501761\n",
            "Epoch: 177 \n",
            "Accuracy: 0.7499999395893313\n",
            "Epoch: 178 \n",
            "Accuracy: 0.7499999427452242\n",
            "Epoch: 179 \n",
            "Accuracy: 0.7499999457283889\n",
            "Epoch: 180 \n",
            "Accuracy: 0.7499999485487256\n",
            "Epoch: 181 \n",
            "Accuracy: 0.7499999512155409\n",
            "Epoch: 182 \n",
            "Accuracy: 0.7499999537375845\n",
            "Epoch: 183 \n",
            "Accuracy: 0.7499999561230841\n",
            "Epoch: 184 \n",
            "Accuracy: 0.7499999583797784\n",
            "Epoch: 185 \n",
            "Accuracy: 0.749999960514947\n",
            "Epoch: 186 \n",
            "Accuracy: 0.7499999625354394\n",
            "Epoch: 187 \n",
            "Accuracy: 0.7499999644477007\n",
            "Epoch: 188 \n",
            "Accuracy: 0.7499999662577975\n",
            "Epoch: 189 \n",
            "Accuracy: 0.7499999679714409\n",
            "Epoch: 190 \n",
            "Accuracy: 0.7499999695940078\n",
            "Epoch: 191 \n",
            "Accuracy: 0.7499999711305618\n",
            "Epoch: 192 \n",
            "Accuracy: 0.7499999725858721\n",
            "Epoch: 193 \n",
            "Accuracy: 0.7499999739644316\n",
            "Epoch: 194 \n",
            "Accuracy: 0.7499999752704734\n",
            "Epoch: 195 \n",
            "Accuracy: 0.7499999765079862\n",
            "Epoch: 196 \n",
            "Accuracy: 0.74999997768073\n",
            "Epoch: 197 \n",
            "Accuracy: 0.7499999787922487\n",
            "Epoch: 198 \n",
            "Accuracy: 0.7499999798458838\n",
            "Epoch: 199 \n",
            "Accuracy: 0.7499999808447861\n",
            "Epoch: 200 \n",
            "Accuracy: 0.7499999817919276\n",
            "Epoch: 201 \n",
            "Accuracy: 0.7499999826901111\n",
            "Epoch: 202 \n",
            "Accuracy: 0.7499999835419814\n",
            "Epoch: 203 \n",
            "Accuracy: 0.7499999843500336\n",
            "Epoch: 204 \n",
            "Accuracy: 0.7499999851166227\n",
            "Epoch: 205 \n",
            "Accuracy: 0.7499999858439714\n",
            "Epoch: 206 \n",
            "Accuracy: 0.7499999865341782\n",
            "Epoch: 207 \n",
            "Accuracy: 0.7499999871892241\n",
            "Epoch: 208 \n",
            "Accuracy: 0.7499999878109798\n",
            "Epoch: 209 \n",
            "Accuracy: 0.7499999884012125\n",
            "Epoch: 210 \n",
            "Accuracy: 0.7499999889615909\n",
            "Epoch: 211 \n",
            "Accuracy: 0.7499999894936918\n",
            "Epoch: 212 \n",
            "Accuracy: 0.7499999899990052\n",
            "Epoch: 213 \n",
            "Accuracy: 0.749999990478939\n",
            "Epoch: 214 \n",
            "Accuracy: 0.7499999909348236\n",
            "Epoch: 215 \n",
            "Accuracy: 0.7499999913679173\n",
            "Epoch: 216 \n",
            "Accuracy: 0.7499999917794091\n",
            "Epoch: 217 \n",
            "Accuracy: 0.7499999921704235\n",
            "Epoch: 218 \n",
            "Accuracy: 0.7499999925420241\n",
            "Epoch: 219 \n",
            "Accuracy: 0.7499999928952166\n",
            "Epoch: 220 \n",
            "Accuracy: 0.7499999932309525\n",
            "Epoch: 221 \n",
            "Accuracy: 0.7499999935501318\n",
            "Epoch: 222 \n",
            "Accuracy: 0.7499999938536066\n",
            "Epoch: 223 \n",
            "Accuracy: 0.7499999941421827\n",
            "Epoch: 224 \n",
            "Accuracy: 0.7499999944166231\n",
            "Epoch: 225 \n",
            "Accuracy: 0.74999999467765\n",
            "Epoch: 226 \n",
            "Accuracy: 0.7499999949259472\n",
            "Epoch: 227 \n",
            "Accuracy: 0.7499999951621619\n",
            "Epoch: 228 \n",
            "Accuracy: 0.7499999953869074\n",
            "Epoch: 229 \n",
            "Accuracy: 0.7499999956007641\n",
            "Epoch: 230 \n",
            "Accuracy: 0.7499999958042822\n",
            "Epoch: 231 \n",
            "Accuracy: 0.7499999959979828\n",
            "Epoch: 232 \n",
            "Accuracy: 0.7499999961823596\n",
            "Epoch: 233 \n",
            "Accuracy: 0.7499999963578801\n",
            "Epoch: 234 \n",
            "Accuracy: 0.7499999965249879\n",
            "Epoch: 235 \n",
            "Accuracy: 0.7499999966841031\n",
            "Epoch: 236 \n",
            "Accuracy: 0.7499999968356243\n",
            "Epoch: 237 \n",
            "Accuracy: 0.7499999969799291\n",
            "Epoch: 238 \n",
            "Accuracy: 0.7499999971173755\n",
            "Epoch: 239 \n",
            "Accuracy: 0.7499999972483034\n",
            "Epoch: 240 \n",
            "Accuracy: 0.7499999973730342\n",
            "Epoch: 241 \n",
            "Accuracy: 0.7499999974918743\n",
            "Epoch: 242 \n",
            "Accuracy: 0.7499999976051128\n",
            "Epoch: 243 \n",
            "Accuracy: 0.7499999977130253\n",
            "Epoch: 244 \n",
            "Accuracy: 0.7499999978158722\n",
            "Epoch: 245 \n",
            "Accuracy: 0.7499999979139016\n",
            "Epoch: 246 \n",
            "Accuracy: 0.749999998007348\n",
            "Epoch: 247 \n",
            "Accuracy: 0.7499999980964349\n",
            "Epoch: 248 \n",
            "Accuracy: 0.7499999981813738\n",
            "Epoch: 249 \n",
            "Accuracy: 0.749999998262366\n",
            "Epoch: 250 \n",
            "Accuracy: 0.7499999983396023\n",
            "Epoch: 251 \n",
            "Accuracy: 0.7499999984132639\n",
            "Epoch: 252 \n",
            "Accuracy: 0.7499999984835233\n",
            "Epoch: 253 \n",
            "Accuracy: 0.7499999985505439\n",
            "Epoch: 254 \n",
            "Accuracy: 0.7499999986144811\n",
            "Epoch: 255 \n",
            "Accuracy: 0.7499999986754825\n",
            "Epoch: 256 \n",
            "Accuracy: 0.7499999987336884\n",
            "Epoch: 257 \n",
            "Accuracy: 0.7499999987892321\n",
            "Epoch: 258 \n",
            "Accuracy: 0.7499999988422404\n",
            "Epoch: 259 \n",
            "Accuracy: 0.7499999988928336\n",
            "Epoch: 260 \n",
            "Accuracy: 0.7499999989411263\n",
            "Epoch: 261 \n",
            "Accuracy: 0.7499999989872271\n",
            "Epoch: 262 \n",
            "Accuracy: 0.7499999990312397\n",
            "Epoch: 263 \n",
            "Accuracy: 0.7499999990732624\n",
            "Epoch: 264 \n",
            "Accuracy: 0.7499999991133888\n",
            "Epoch: 265 \n",
            "Accuracy: 0.7499999991517078\n",
            "Epoch: 266 \n",
            "Accuracy: 0.7499999991883042\n",
            "Epoch: 267 \n",
            "Accuracy: 0.7499999992232584\n",
            "Epoch: 268 \n",
            "Accuracy: 0.7499999992566472\n",
            "Epoch: 269 \n",
            "Accuracy: 0.7499999992885433\n",
            "Epoch: 270 \n",
            "Accuracy: 0.7499999993190163\n",
            "Epoch: 271 \n",
            "Accuracy: 0.7499999993481321\n",
            "Epoch: 272 \n",
            "Accuracy: 0.7499999993759534\n",
            "Epoch: 273 \n",
            "Accuracy: 0.7499999994025403\n",
            "Epoch: 274 \n",
            "Accuracy: 0.7499999994279495\n",
            "Epoch: 275 \n",
            "Accuracy: 0.7499999994522353\n",
            "Epoch: 276 \n",
            "Accuracy: 0.7499999994754494\n",
            "Epoch: 277 \n",
            "Accuracy: 0.7499999994976407\n",
            "Epoch: 278 \n",
            "Accuracy: 0.7499999995188564\n",
            "Epoch: 279 \n",
            "Accuracy: 0.7499999995391409\n",
            "Epoch: 280 \n",
            "Accuracy: 0.7499999995585366\n",
            "Epoch: 281 \n",
            "Accuracy: 0.749999999577084\n",
            "Epoch: 282 \n",
            "Accuracy: 0.7499999995948217\n",
            "Epoch: 283 \n",
            "Accuracy: 0.7499999996117863\n",
            "Epoch: 284 \n",
            "Accuracy: 0.7499999996280129\n",
            "Epoch: 285 \n",
            "Accuracy: 0.7499999996435349\n",
            "Epoch: 286 \n",
            "Accuracy: 0.7499999996583839\n",
            "Epoch: 287 \n",
            "Accuracy: 0.7499999996725906\n",
            "Epoch: 288 \n",
            "Accuracy: 0.7499999996861834\n",
            "Epoch: 289 \n",
            "Accuracy: 0.7499999996991901\n",
            "Epoch: 290 \n",
            "Accuracy: 0.7499999997116368\n",
            "Epoch: 291 \n",
            "Accuracy: 0.7499999997235487\n",
            "Epoch: 292 \n",
            "Accuracy: 0.7499999997349495\n",
            "Epoch: 293 \n",
            "Accuracy: 0.7499999997458621\n",
            "Epoch: 294 \n",
            "Accuracy: 0.749999999756308\n",
            "Epoch: 295 \n",
            "Accuracy: 0.7499999997663083\n",
            "Epoch: 296 \n",
            "Accuracy: 0.7499999997758824\n",
            "Epoch: 297 \n",
            "Accuracy: 0.7499999997850493\n",
            "Epoch: 298 \n",
            "Accuracy: 0.7499999997938268\n",
            "Epoch: 299 \n",
            "Accuracy: 0.7499999998022322\n",
            "Epoch: 300 \n",
            "Accuracy: 0.7499999998102821\n",
            "Epoch: 301 \n",
            "Accuracy: 0.7499999998179917\n",
            "Epoch: 302 \n",
            "Accuracy: 0.7499999998253761\n",
            "Epoch: 303 \n",
            "Accuracy: 0.7499999998324498\n",
            "Epoch: 304 \n",
            "Accuracy: 0.7499999998392258\n",
            "Epoch: 305 \n",
            "Accuracy: 0.7499999998457176\n",
            "Epoch: 306 \n",
            "Accuracy: 0.7499999998519373\n",
            "Epoch: 307 \n",
            "Accuracy: 0.7499999998578969\n",
            "Epoch: 308 \n",
            "Accuracy: 0.7499999998636075\n",
            "Epoch: 309 \n",
            "Accuracy: 0.7499999998690801\n",
            "Epoch: 310 \n",
            "Accuracy: 0.7499999998743248\n",
            "Epoch: 311 \n",
            "Accuracy: 0.7499999998793516\n",
            "Epoch: 312 \n",
            "Accuracy: 0.7499999998841698\n",
            "Epoch: 313 \n",
            "Accuracy: 0.7499999998887883\n",
            "Epoch: 314 \n",
            "Accuracy: 0.7499999998932158\n",
            "Epoch: 315 \n",
            "Accuracy: 0.7499999998974605\n",
            "Epoch: 316 \n",
            "Accuracy: 0.7499999999015302\n",
            "Epoch: 317 \n",
            "Accuracy: 0.7499999999054323\n",
            "Epoch: 318 \n",
            "Accuracy: 0.7499999999091742\n",
            "Epoch: 319 \n",
            "Accuracy: 0.7499999999127624\n",
            "Epoch: 320 \n",
            "Accuracy: 0.7499999999162037\n",
            "Epoch: 321 \n",
            "Accuracy: 0.7499999999195043\n",
            "Epoch: 322 \n",
            "Accuracy: 0.74999999992267\n",
            "Epoch: 323 \n",
            "Accuracy: 0.7499999999257065\n",
            "Epoch: 324 \n",
            "Accuracy: 0.7499999999286195\n",
            "Epoch: 325 \n",
            "Accuracy: 0.7499999999314142\n",
            "Epoch: 326 \n",
            "Accuracy: 0.7499999999340954\n",
            "Epoch: 327 \n",
            "Accuracy: 0.7499999999366679\n",
            "Epoch: 328 \n",
            "Accuracy: 0.7499999999391364\n",
            "Epoch: 329 \n",
            "Accuracy: 0.749999999941505\n",
            "Epoch: 330 \n",
            "Accuracy: 0.7499999999437782\n",
            "Epoch: 331 \n",
            "Accuracy: 0.7499999999459598\n",
            "Epoch: 332 \n",
            "Accuracy: 0.7499999999480537\n",
            "Epoch: 333 \n",
            "Accuracy: 0.7499999999500635\n",
            "Epoch: 334 \n",
            "Accuracy: 0.7499999999519926\n",
            "Epoch: 335 \n",
            "Accuracy: 0.7499999999538447\n",
            "Epoch: 336 \n",
            "Accuracy: 0.7499999999556226\n",
            "Epoch: 337 \n",
            "Accuracy: 0.7499999999573297\n",
            "Epoch: 338 \n",
            "Accuracy: 0.7499999999589686\n",
            "Epoch: 339 \n",
            "Accuracy: 0.7499999999605425\n",
            "Epoch: 340 \n",
            "Accuracy: 0.7499999999620535\n",
            "Epoch: 341 \n",
            "Accuracy: 0.7499999999635049\n",
            "Epoch: 342 \n",
            "Accuracy: 0.7499999999648985\n",
            "Epoch: 343 \n",
            "Accuracy: 0.7499999999662372\n",
            "Epoch: 344 \n",
            "Accuracy: 0.7499999999675229\n",
            "Epoch: 345 \n",
            "Accuracy: 0.7499999999687581\n",
            "Epoch: 346 \n",
            "Accuracy: 0.7499999999699444\n",
            "Epoch: 347 \n",
            "Accuracy: 0.7499999999710841\n",
            "Epoch: 348 \n",
            "Accuracy: 0.7499999999721791\n",
            "Epoch: 349 \n",
            "Accuracy: 0.7499999999732312\n",
            "Epoch: 350 \n",
            "Accuracy: 0.7499999999742419\n",
            "Epoch: 351 \n",
            "Accuracy: 0.7499999999752133\n",
            "Epoch: 352 \n",
            "Accuracy: 0.7499999999761466\n",
            "Epoch: 353 \n",
            "Accuracy: 0.7499999999770437\n",
            "Epoch: 354 \n",
            "Accuracy: 0.7499999999779058\n",
            "Epoch: 355 \n",
            "Accuracy: 0.7499999999787343\n",
            "Epoch: 356 \n",
            "Accuracy: 0.7499999999795308\n",
            "Epoch: 357 \n",
            "Accuracy: 0.7499999999802963\n",
            "Epoch: 358 \n",
            "Accuracy: 0.7499999999810322\n",
            "Epoch: 359 \n",
            "Accuracy: 0.7499999999817396\n",
            "Epoch: 360 \n",
            "Accuracy: 0.7499999999824197\n",
            "Epoch: 361 \n",
            "Accuracy: 0.7499999999830735\n",
            "Epoch: 362 \n",
            "Accuracy: 0.7499999999837024\n",
            "Epoch: 363 \n",
            "Accuracy: 0.749999999984307\n",
            "Epoch: 364 \n",
            "Accuracy: 0.7499999999848883\n",
            "Epoch: 365 \n",
            "Accuracy: 0.7499999999854474\n",
            "Epoch: 366 \n",
            "Accuracy: 0.749999999985985\n",
            "Epoch: 367 \n",
            "Accuracy: 0.7499999999865021\n",
            "Epoch: 368 \n",
            "Accuracy: 0.7499999999869995\n",
            "Epoch: 369 \n",
            "Accuracy: 0.7499999999874779\n",
            "Epoch: 370 \n",
            "Accuracy: 0.7499999999879381\n",
            "Epoch: 371 \n",
            "Accuracy: 0.7499999999883808\n",
            "Epoch: 372 \n",
            "Accuracy: 0.7499999999888067\n",
            "Epoch: 373 \n",
            "Accuracy: 0.7499999999892164\n",
            "Epoch: 374 \n",
            "Accuracy: 0.7499999999896106\n",
            "Epoch: 375 \n",
            "Accuracy: 0.74999999998999\n",
            "Epoch: 376 \n",
            "Accuracy: 0.749999999990355\n",
            "Epoch: 377 \n",
            "Accuracy: 0.7499999999907062\n",
            "Epoch: 378 \n",
            "Accuracy: 0.7499999999910442\n",
            "Epoch: 379 \n",
            "Accuracy: 0.7499999999913695\n",
            "Epoch: 380 \n",
            "Accuracy: 0.7499999999916825\n",
            "Epoch: 381 \n",
            "Accuracy: 0.749999999991984\n",
            "Epoch: 382 \n",
            "Accuracy: 0.749999999992274\n",
            "Epoch: 383 \n",
            "Accuracy: 0.7499999999925531\n",
            "Epoch: 384 \n",
            "Accuracy: 0.7499999999928217\n",
            "Epoch: 385 \n",
            "Accuracy: 0.7499999999930805\n",
            "Epoch: 386 \n",
            "Accuracy: 0.7499999999933296\n",
            "Epoch: 387 \n",
            "Accuracy: 0.7499999999935694\n",
            "Epoch: 388 \n",
            "Accuracy: 0.7499999999938003\n",
            "Epoch: 389 \n",
            "Accuracy: 0.7499999999940227\n",
            "Epoch: 390 \n",
            "Accuracy: 0.7499999999942367\n",
            "Epoch: 391 \n",
            "Accuracy: 0.7499999999944429\n",
            "Epoch: 392 \n",
            "Accuracy: 0.7499999999946414\n",
            "Epoch: 393 \n",
            "Accuracy: 0.7499999999948327\n",
            "Epoch: 394 \n",
            "Accuracy: 0.7499999999950168\n",
            "Epoch: 395 \n",
            "Accuracy: 0.7499999999951941\n",
            "Epoch: 396 \n",
            "Accuracy: 0.749999999995365\n",
            "Epoch: 397 \n",
            "Accuracy: 0.7499999999955296\n",
            "Epoch: 398 \n",
            "Accuracy: 0.7499999999956881\n",
            "Epoch: 399 \n",
            "Accuracy: 0.7499999999958408\n",
            "Epoch: 400 \n",
            "Accuracy: 0.7499999999959879\n",
            "Epoch: 401 \n",
            "Accuracy: 0.7499999999961297\n",
            "Epoch: 402 \n",
            "Accuracy: 0.7499999999962663\n",
            "Epoch: 403 \n",
            "Accuracy: 0.7499999999963978\n",
            "Epoch: 404 \n",
            "Accuracy: 0.7499999999965247\n",
            "Epoch: 405 \n",
            "Accuracy: 0.7499999999966469\n",
            "Epoch: 406 \n",
            "Accuracy: 0.7499999999967646\n",
            "Epoch: 407 \n",
            "Accuracy: 0.749999999996878\n",
            "Epoch: 408 \n",
            "Accuracy: 0.7499999999969875\n",
            "Epoch: 409 \n",
            "Accuracy: 0.7499999999970928\n",
            "Epoch: 410 \n",
            "Accuracy: 0.7499999999971945\n",
            "Epoch: 411 \n",
            "Accuracy: 0.7499999999972924\n",
            "Epoch: 412 \n",
            "Accuracy: 0.7499999999973868\n",
            "Epoch: 413 \n",
            "Accuracy: 0.7499999999974778\n",
            "Epoch: 414 \n",
            "Accuracy: 0.7499999999975655\n",
            "Epoch: 415 \n",
            "Accuracy: 0.7499999999976501\n",
            "Epoch: 416 \n",
            "Accuracy: 0.7499999999977316\n",
            "Epoch: 417 \n",
            "Accuracy: 0.7499999999978102\n",
            "Epoch: 418 \n",
            "Accuracy: 0.749999999997886\n",
            "Epoch: 419 \n",
            "Accuracy: 0.7499999999979592\n",
            "Epoch: 420 \n",
            "Accuracy: 0.7499999999980296\n",
            "Epoch: 421 \n",
            "Accuracy: 0.7499999999980976\n",
            "Epoch: 422 \n",
            "Accuracy: 0.7499999999981631\n",
            "Epoch: 423 \n",
            "Accuracy: 0.7499999999982264\n",
            "Epoch: 424 \n",
            "Accuracy: 0.7499999999982874\n",
            "Epoch: 425 \n",
            "Accuracy: 0.7499999999983462\n",
            "Epoch: 426 \n",
            "Accuracy: 0.7499999999984028\n",
            "Epoch: 427 \n",
            "Accuracy: 0.7499999999984576\n",
            "Epoch: 428 \n",
            "Accuracy: 0.7499999999985103\n",
            "Epoch: 429 \n",
            "Accuracy: 0.7499999999985614\n",
            "Epoch: 430 \n",
            "Accuracy: 0.7499999999986104\n",
            "Epoch: 431 \n",
            "Accuracy: 0.7499999999986577\n",
            "Epoch: 432 \n",
            "Accuracy: 0.7499999999987035\n",
            "Epoch: 433 \n",
            "Accuracy: 0.7499999999987477\n",
            "Epoch: 434 \n",
            "Accuracy: 0.7499999999987902\n",
            "Epoch: 435 \n",
            "Accuracy: 0.7499999999988313\n",
            "Epoch: 436 \n",
            "Accuracy: 0.7499999999988709\n",
            "Epoch: 437 \n",
            "Accuracy: 0.7499999999989091\n",
            "Epoch: 438 \n",
            "Accuracy: 0.749999999998946\n",
            "Epoch: 439 \n",
            "Accuracy: 0.7499999999989817\n",
            "Epoch: 440 \n",
            "Accuracy: 0.749999999999016\n",
            "Epoch: 441 \n",
            "Accuracy: 0.7499999999990492\n",
            "Epoch: 442 \n",
            "Accuracy: 0.7499999999990812\n",
            "Epoch: 443 \n",
            "Accuracy: 0.7499999999991122\n",
            "Epoch: 444 \n",
            "Accuracy: 0.749999999999142\n",
            "Epoch: 445 \n",
            "Accuracy: 0.7499999999991709\n",
            "Epoch: 446 \n",
            "Accuracy: 0.7499999999991986\n",
            "Epoch: 447 \n",
            "Accuracy: 0.7499999999992255\n",
            "Epoch: 448 \n",
            "Accuracy: 0.7499999999992513\n",
            "Epoch: 449 \n",
            "Accuracy: 0.7499999999992764\n",
            "Epoch: 450 \n",
            "Accuracy: 0.7499999999993006\n",
            "Epoch: 451 \n",
            "Accuracy: 0.7499999999993239\n",
            "Epoch: 452 \n",
            "Accuracy: 0.7499999999993463\n",
            "Epoch: 453 \n",
            "Accuracy: 0.7499999999993682\n",
            "Epoch: 454 \n",
            "Accuracy: 0.7499999999993892\n",
            "Epoch: 455 \n",
            "Accuracy: 0.7499999999994094\n",
            "Epoch: 456 \n",
            "Accuracy: 0.749999999999429\n",
            "Epoch: 457 \n",
            "Accuracy: 0.749999999999448\n",
            "Epoch: 458 \n",
            "Accuracy: 0.7499999999994662\n",
            "Epoch: 459 \n",
            "Accuracy: 0.7499999999994837\n",
            "Epoch: 460 \n",
            "Accuracy: 0.7499999999995008\n",
            "Epoch: 461 \n",
            "Accuracy: 0.7499999999995173\n",
            "Epoch: 462 \n",
            "Accuracy: 0.7499999999995333\n",
            "Epoch: 463 \n",
            "Accuracy: 0.7499999999995486\n",
            "Epoch: 464 \n",
            "Accuracy: 0.7499999999995635\n",
            "Epoch: 465 \n",
            "Accuracy: 0.7499999999995779\n",
            "Epoch: 466 \n",
            "Accuracy: 0.7499999999995917\n",
            "Epoch: 467 \n",
            "Accuracy: 0.749999999999605\n",
            "Epoch: 468 \n",
            "Accuracy: 0.749999999999618\n",
            "Epoch: 469 \n",
            "Accuracy: 0.7499999999996305\n",
            "Epoch: 470 \n",
            "Accuracy: 0.7499999999996425\n",
            "Epoch: 471 \n",
            "Accuracy: 0.7499999999996543\n",
            "Epoch: 472 \n",
            "Accuracy: 0.7499999999996655\n",
            "Epoch: 473 \n",
            "Accuracy: 0.7499999999996765\n",
            "Epoch: 474 \n",
            "Accuracy: 0.7499999999996869\n",
            "Epoch: 475 \n",
            "Accuracy: 0.7499999999996971\n",
            "Epoch: 476 \n",
            "Accuracy: 0.7499999999997069\n",
            "Epoch: 477 \n",
            "Accuracy: 0.7499999999997164\n",
            "Epoch: 478 \n",
            "Accuracy: 0.7499999999997257\n",
            "Epoch: 479 \n",
            "Accuracy: 0.7499999999997344\n",
            "Epoch: 480 \n",
            "Accuracy: 0.7499999999997431\n",
            "Epoch: 481 \n",
            "Accuracy: 0.7499999999997514\n",
            "Epoch: 482 \n",
            "Accuracy: 0.7499999999997595\n",
            "Epoch: 483 \n",
            "Accuracy: 0.7499999999997672\n",
            "Epoch: 484 \n",
            "Accuracy: 0.7499999999997747\n",
            "Epoch: 485 \n",
            "Accuracy: 0.749999999999782\n",
            "Epoch: 486 \n",
            "Accuracy: 0.749999999999789\n",
            "Epoch: 487 \n",
            "Accuracy: 0.7499999999997957\n",
            "Epoch: 488 \n",
            "Accuracy: 0.7499999999998024\n",
            "Epoch: 489 \n",
            "Accuracy: 0.7499999999998086\n",
            "Epoch: 490 \n",
            "Accuracy: 0.7499999999998147\n",
            "Epoch: 491 \n",
            "Accuracy: 0.7499999999998207\n",
            "Epoch: 492 \n",
            "Accuracy: 0.7499999999998264\n",
            "Epoch: 493 \n",
            "Accuracy: 0.7499999999998319\n",
            "Epoch: 494 \n",
            "Accuracy: 0.7499999999998372\n",
            "Epoch: 495 \n",
            "Accuracy: 0.7499999999998425\n",
            "Epoch: 496 \n",
            "Accuracy: 0.7499999999998475\n",
            "Epoch: 497 \n",
            "Accuracy: 0.7499999999998523\n",
            "Epoch: 498 \n",
            "Accuracy: 0.749999999999857\n",
            "Epoch: 499 \n",
            "Accuracy: 0.7499999999998616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpkPKx-6luca"
      },
      "source": [
        "# create two new examples to predict                                   \n",
        "example1 = np.array([[1, 0, 0]])\n",
        "example2 = np.array([[0, 1, 1]])\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLD0rL1Dl0yi",
        "outputId": "4d09d403-44e5-4766-f101-def88c57b454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# print the predictions for both examples                                   \n",
        "print(softNN.predict(example1), ' - Correct: ', example1[0][0])\n",
        "print(softNN.predict(example2), ' - Correct: ', example2[0][0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.]]  - Correct:  1\n",
            "[[1.]]  - Correct:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se-EUcz6mCag",
        "outputId": "9be276b7-0250-488e-9d25-13361c0801ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "# plot the error over the entire training duration\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(softNN.epoch_list, softNN.error_history)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}